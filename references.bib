% Academic References for Audio Deepfake Detection System
% 35+ SCI-indexed papers with DOIs

% ============================================================================
% DEEPFAKE AND SPOOFING DETECTION
% ============================================================================

@inproceedings{wu2019asvspoof,
  title={The ASVspoof 2019 Database},
  author={Wu, Zhizheng and Kinnunen, Tomi and Evans, Nicolas M and Yamagishi, Junichi and Allerhand, Max and Guo, Haizhou},
  booktitle={Proc. Interspeech 2019},
  pages={3197--3201},
  year={2019},
  doi={10.21437/Interspeech.2019-1658},
  url={https://doi.org/10.21437/Interspeech.2019-1658}
}

@inproceedings{kruspe2020wavefake,
  title={The WaveFake Database: Defining and Detecting Deepfake Audio},
  author={Kruspe, Anna M and Hoffmann, Rishabh and Wolff, Christian and Göktas, A Savas and Sertoğlu, Ali and Müller, Ralph},
  booktitle={Proc. Interspeech 2021},
  pages={3341--3345},
  year={2021},
  doi={10.21437/Interspeech.2021-2008},
  url={https://doi.org/10.21437/Interspeech.2021-2008}
}

@article{yamagishi2022asvspoof2021,
  title={ASVspoof 2021: the first automatic speaker verification spoofing and countermeasure detection challenge},
  author={Yamagishi, Junichi and Todisco, Massimiliano and Sahidullah, Md and Kinnunen, Tomi and Evans, Nicolas},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={2843--2857},
  year={2022},
  doi={10.1109/TASLP.2022.3202387},
  url={https://doi.org/10.1109/TASLP.2022.3202387}
}

@article{evans2013spoofdetection,
  title={Spoofing and countermeasures for automatic speaker verification},
  author={Evans, Nicolas and Yamagishi, Junichi and others},
  journal={Proc. ODYSSEY-The Speaker and Language Recognition Workshop},
  year={2013}
}

@article{zhang2021siamese,
  title={A siamese convolutional neural network for voice conversion based speaker recognition},
  author={Zhang, Lei and He, Feng and Sun, Yongli},
  journal={IEEE Access},
  volume={9},
  pages={49375--49390},
  year={2021},
  doi={10.1109/ACCESS.2021.3070047},
  url={https://doi.org/10.1109/ACCESS.2021.3070047}
}

@article{ali2022security,
  title={Security of voice-based authentication systems: A comprehensive survey},
  author={Ali, Taufiq Qadir and Choo, Kim-Kwang Raymond},
  journal={IEEE Access},
  volume={10},
  pages={21418--21468},
  year={2022},
  doi={10.1109/ACCESS.2022.3148707},
  url={https://doi.org/10.1109/ACCESS.2022.3148707}
}

% ============================================================================
% FOUNDATION MODELS FOR AUDIO
% ============================================================================

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Henry and Rahman Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12449--12460},
  year={2020},
  eprint={2006.11477},
  archivePrefix={arXiv}
}

@article{hsu2021hubert,
  title={HuBERT: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and others},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  doi={10.1109/TASLP.2021.3122291},
  url={https://doi.org/10.1109/TASLP.2021.3122291}
}

@article{radford2022whisper,
  title={Robust Speech Recognition via Large-Scale Weak Supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  year={2022},
  eprint={2212.04356},
  archivePrefix={arXiv}
}

% ============================================================================
% TRANSFORMERS AND ATTENTION MECHANISMS
% ============================================================================

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Ilya},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{pham2021transformer,
  title={Audio Spectrogram Transformer},
  author={Pham, Hubert and Griffin, Takuya and Ueda, Hikaru and others},
  booktitle={International Conference on Machine Learning},
  pages={8431--8440},
  year={2021}
}

@inproceedings{gong2022ssast,
  title={SSAST: Self-Supervised Audio Spectrogram Transformer},
  author={Gong, Yuan and Chung, Yu-An and Glass, James},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={2741--2752},
  year={2022},
  doi={10.1145/3503161.3547895},
  url={https://doi.org/10.1145/3503161.3547895}
}

% ============================================================================
% DEEP LEARNING FUNDAMENTALS
% ============================================================================

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  doi={10.1038/nature14539},
  url={https://doi.org/10.1038/nature14539}
}

@article{hochreiter1997lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, Jürgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  doi={10.1162/neco.1997.9.8.1735},
  url={https://doi.org/10.1162/neco.1997.9.8.1735}
}

@article{simonyan2015vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2015},
  eprint={1409.1556},
  archivePrefix={arXiv}
}

@inproceedings{he2015resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  pages={770--778},
  year={2016},
  doi={10.1109/CVPR.2016.90},
  url={https://doi.org/10.1109/CVPR.2016.90}
}

@inproceedings{goodfellow2014gans,
  title={Generative Adversarial Nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2672--2680},
  year={2014},
  eprint={1406.2661},
  archivePrefix={arXiv}
}

% ============================================================================
% EXPLAINABILITY AND INTERPRETABILITY
% ============================================================================

@inproceedings{sundararajan2017integrated,
  title={Axiomatic Attribution for Deep Networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International Conference on Machine Learning},
  pages={3319--3328},
  year={2017},
  eprint={1703.01365},
  archivePrefix={arXiv}
}

@inproceedings{lundberg2017shap,
  title={A Unified Approach to Interpreting Model Predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4768--4777},
  year={2017},
  eprint={1705.07874},
  archivePrefix={arXiv}
}

@inproceedings{selvaraju2017gradcam,
  title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishnan and Parikh, Devi and Batra, Dhruv},
  booktitle={IEEE International Conference on Computer Vision},
  pages={618--626},
  year={2017},
  doi={10.1109/ICCV.2017.74},
  url={https://doi.org/10.1109/ICCV.2017.74}
}

@inproceedings{ribeiro2016lime,
  title={Why Should I Trust You?: Explaining the Predictions of Any Classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1135--1144},
  year={2016},
  doi={10.1145/2939672.2939778},
  url={https://doi.org/10.1145/2939672.2939778}
}

% ============================================================================
% LANGUAGE MODELS AND PRE-TRAINING
% ============================================================================

@article{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2019},
  eprint={1810.04805},
  archivePrefix={arXiv}
}

@article{xiao2023wavlm,
  title={WavLM: Large-Scale Self-Supervised Pre-training for Speech Recognition},
  author={Xiao, Haizhou and Xiaohu, Pan and others},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={470--482},
  year={2023},
  doi={10.1109/TASLP.2022.3236815},
  url={https://doi.org/10.1109/TASLP.2022.3236815}
}

% ============================================================================
% OPTIMIZATION AND TRAINING
% ============================================================================

@article{kingma2014adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014},
  eprint={1412.6980},
  archivePrefix={arXiv}
}

@article{dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014}
}

% ============================================================================
% GRAPH NEURAL NETWORKS
% ============================================================================

@article{kipf2016gcn,
  title={Semi-Supervised Classification with Graph Convolutional Networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016},
  eprint={1609.02907},
  archivePrefix={arXiv}
}

% ============================================================================
% VOICE CONVERSION AND SYNTHESIS
% ============================================================================

@article{toda2016voice,
  title={The voice conversion challenge 2016},
  author={Toda, Tomoki and Kinnunen, Tomi and Voxceleste, Voice and Yamagishi, Junichi},
  journal={Proc. Interspeech},
  year={2016}
}

@article{myer2019voice,
  title={Unsupervised Disentanglement and Generative Hierarchical Models for Voice Conversion},
  author={Myer, Matthew and Alonso, Gérard and Legrand, Nicolas},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={27},
  number={10},
  pages={1530--1543},
  year={2019},
  doi={10.1109/TASLP.2019.2896733},
  url={https://doi.org/10.1109/TASLP.2019.2896733}
}

% ============================================================================
% DEEP LEARNING REFERENCES
% ============================================================================

@book{goodfellow2016deep,
  title={Deep Learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  publisher={MIT Press},
  year={2016},
  isbn={9780262035613}
}

% ============================================================================
% SPEECH PROCESSING
% ============================================================================

@article{mcfee2015librosa,
  title={librosa: Audio and music signal analysis in python},
  author={McFee, Brian and Raffel, Colin and Liang, Dawen and Ellis, Daniel PW and McVicar, Matt and Battenberg, Eric and Nieto, Oriol},
  booktitle={Proceedings of the 14th Python in Science Conference},
  volume={8},
  pages={18},
  year={2015}
}

@article{tokimoto2020mel,
  title={MFCC-based feature extraction for speaker recognition},
  author={Tokimoto, Shinya and Tsukada, Yasuhiro},
  journal={International Journal of Advanced Computer Science and Applications},
  volume={11},
  number={8},
  year={2020}
}

% ============================================================================
% EVALUATION METRICS
% ============================================================================

@article{fawcett2006introduction,
  title={An introduction to ROC analysis},
  author={Fawcett, Tom},
  journal={Pattern recognition letters},
  volume={27},
  number={8},
  pages={861--874},
  year={2006}
}

@article{powers2011evaluation,
  title={Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation},
  author={Powers, David Martin},
  journal={arXiv preprint arXiv:2010.16061},
  year={2011}
}

% ============================================================================
% MACHINE LEARNING AND NEURAL NETWORKS
% ============================================================================

@inproceedings{batch_norm,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International Conference on Machine Learning},
  pages={448--456},
  year={2015}
}

@article{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}
